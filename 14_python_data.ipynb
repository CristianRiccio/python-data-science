{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data science in Python\n",
    "\n",
    "- Course GitHub repo: https://github.com/pycam/python-data-science\n",
    "- Python website: https://www.python.org/ \n",
    "\n",
    "## Session 1.4: Working with Pandas\n",
    "\n",
    "- [Reading CSV Data Using Pandas](#Reading-CSV-Data-Using-Pandas)\n",
    "- [Exploring our data](#Exploring-our-data)\n",
    "- [Writing data](#Writing-data)\n",
    "- [Exercise 1.4.1](#Exercise-1.4.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV Data Using Pandas\n",
    "\n",
    "### Import the Pandas library\n",
    "\n",
    "Pandas is a widely-used external Python library for statistics, particularly on tabular data.\n",
    "It borrows many features from R’s dataframes.\n",
    "A dataframe is a 2-dimentional table whose columns have names and potentially have different data types.\n",
    "\n",
    "To load `pandas` into your environment, you first need to install it using `pip install pandas` as it is an external third-party library, it is not included by default when you install Python.\n",
    "\n",
    "When installed, to load it, use `import pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV data\n",
    "\n",
    "For reading a Comma Separate Values (CSV) data file with pandas, we use `pandas.read_csv()`:\n",
    "\n",
    "- Argument is the name of the file to be read.\n",
    "- Assign result to a variable to store the data that was read.\n",
    "\n",
    "\n",
    "The columns in a dataframe are the observed variables, and the rows are the observations. We are going to load a slightly different Gapminder dataset for Oceania, where each columns represent the GDP per capita on different years and each rows a country in Oceania. \n",
    "\n",
    "Pandas uses backslash `\\` to show wrapped lines when output is too wide to fit the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('data/gapminder_gdp_asia.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our course stores its data files in a `data/` sub-directory, which is why the path to the file is `data/gapminder_gdp_oceania.csv`. If you forget to include `data/`, or if you include it but your copy of the file is somewhere else, you will get a runtime error that ends with a line like this:\n",
    "```\n",
    "FileNotFoundError: File b'gapminder_gdp_oceania.csv' does not exist\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring our data\n",
    "\n",
    "A DataFrame is a 2-dimensional data structure that can store data of different types (including characters, integers, floating point values, factors and more) in columns. It is similar to a spreadsheet or an SQL table or the `data.frame` in R. A DataFrame always has an index (0-based). An index refers to the position of an element in the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, it’s a `DataFrame` (or, to use the full name that Python uses to refer to it internally, a `pandas.core.frame.DataFrame`).\n",
    "\n",
    "It has 2 rows and 13 columns. It uses 288 bytes of memory.\n",
    "\n",
    "The row headings are numbers (0 and 1 in this case) but we really want to index this DataFrame by country. To do so, we pass the name of the column to `read_csv()` as its `index_col` parameter to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('data/gapminder_gdp_asia.csv', index_col='country')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `type()` function to see what kind of thing data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what kind of things does data contain, DataFrames have an attribute called dtypes which returns the data type of each columns. Note that this is an attribute associated to the DataFrame data, and not a method. So do not use `()` to call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has now 2 rows named 'Australia' and 'New Zealand' and 12 columns, each of which has two actual 64-bit floating point values. It uses 208 bytes of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to summarize and access the data stored in DataFrames, using attributes and methods provided by the [DataFrame object](https://pandas.pydata.org/pandas-docs/stable/api.html#dataframe).\n",
    "\n",
    "To access an attribute, use the DataFrame object name followed by the attribute name `df_object.attribute`. Using the DataFrame `data` and attribute `columns`, an index of all the column names in the DataFrame can be accessed with `data.columns`.\n",
    "\n",
    "Methods are called in a similar fashion using the syntax `df_object.method()`. As an example, `data.head()` gets the first few rows in the DataFrame `data` using the `head()` method. With a method, we can supply extra information in the parenthesis as arguments to control behaviour.\n",
    "\n",
    "Let’s look at the data using these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('data/gapminder_gdp_europe.csv', index_col='country')\n",
    "print(data)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gdpPercap_1962.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gdpPercap_1962.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gdpPercap_1962.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing data\n",
    "\n",
    "As well as the `read_csv()` function for reading data from a file, Pandas provides a `to_csv()` function to write dataframes to files. Applying what you’ve learned about reading from files, write one of your dataframes to a file called processed.csv. You can use help to get information on how to use to_csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.4.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
